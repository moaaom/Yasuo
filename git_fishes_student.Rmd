---
title: "Git, GitHub & Ocean Acidification"
author: "Yusheng_Wang_u7457423"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    code_folding: show
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits=2)
```

# **Introduction**

This tutorial will draw on the skills you have already learnt on data visualisation, data wrangling and NHST to analyse a data set on ocean acidification effects on fish behaviour. However, we'll do that in the context of some new workflows that adopt Git and GitHub. 

Use this Rmarkdown file as your template to complete the tasks outlined within the instructions. There are questions asked in the instructions and here in the RMarkdown file. Answer these as best as you can to document your steps and thinking. There are also a series of coding exercises. 

Throughout we are also going to learn a bit more about how to format Rmarkdown documents. So, pay close attention to the formatting. We're also going to make use of the `bookdown` package now to render your Rmarkdown because, well, it's quite elegant in many ways. Before you start the tasks install the following packages:

```{r loadpacks, message=FALSE, results='hide', eval = T}
# Install a load of packages that we'll use. I'll show you a shortcut that I love to use. Try using the p_load function in the "pacman" package. p_load will execute both the install.packages and library commands in one shot so they only need to be used once to install pacman itself.
library(pacman)

# Install bookdown for rendering because we'll need this. While we're at it, lets also install /load the tidyverse
p_load(bookdown, tidyverse, ggforce, flextable, latex2exp, png, magick, patchwork) # basically just list all the packages you want here

```

# **Task 1**

### Provide the link to your GitHub Repo 

While the tasks are meant to get you familiar with how *GitHub* works you should try and make regular commits as you work your way through. We want to see how often you're using *Git*. Below, within the `()` brackets provide the link to your GitHub Repo. Just cut and paste it so we know what the repo name is and where it is. 

[My GitHub Repository](https://github.com/moaaom/Yasuo.git)

By adding the link in the `()` brackets it will hyperlink "My GitHub Repository". This is how to hyperlink in Rmarkdown documents.


# **Task 2**

This task involves cloning your repository on your computer. Where should we place this repository? While GitHub is somewhat of a cloud storage system because it's keeping record of your commits, files and changes in the cloud it is **not** a backup of your files (note that placing `**` around a word will bold it whereas `*` around a word will italicise it). The lack of *GitHub* being a file backup system is important to recognise! 

>**Question 1**: Why should you not rely on *GitHub* as a backup?

```{r, answer1, echo=TRUE, eval = FALSE}
# Write your answer here
1. Backup software provides automatic backup function, while Github requires manual push.
2. Backup software is private, while Github is public (at least among colleagues) â€” If a chunk is not fully complete, you probably do not want to share it online.
3. Github will not be able to track files of commercial softwares like Word and Excel.
4. Github is easyly to have a conflict if you have mane colleagues working at the same time.
5. Github provides more record of the detailed history, which you may not want to pay attention to sometimes.
6. Files in Github can be edided by many people, so it is hard to find the lastest file edited by you quickly if you have many colleagues.
```

I'd usually suggest placing your repo in a cloud storage system like, *OneDrive*, *Dropbox*, or *GoogleDrive*. These will ensure that all your files are backed up and *GitHub* will provide a record of the detailed history. 

Before moving on you might have noticed that the code block above has a name `answer1` and I've added an argument `echo = TRUE`. It's good to label code blocks with useful names to help you debug when rendering of your document goes wrong (when, not IF!). These names need to all be unique. There are a whole bunch of arguments that you can list within code chunks that tell each chunk what to do. You can look to the great [Rmarkdown cheetsheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) for more information.

>**Question 2**: In the second code block called `answer1` if we change echo = TRUE to echo = FALSE what will happen to the code block `answer1` when you render it?

```{r answer2, echo=TRUE, eval = FALSE}
# Write your answer here
The effect of option "echo" is to argue whether to display code along with its results. So, if we change to echo = F, the chuck will not show in markdown file (because there is also a "eval = F", which means do not run it).
```

**Important**: Notice that `eval = FALSE` for many code chunks. When you complete the tasks. Make sure to change these to `TRUE` otherwise you will find your code does not run!

# **Task 3**

Hopefully you have now successfully cloned down your *GitHub* repo. This is your new working directory from which your project will develop. 

Hopefully you also created and/or downloaded the following files and added them to your cloned repo:

1) created a new RStudio project file in your working directory
2) download the `OA_activitydat_20190302_BIOL3207.csv` from Wattle and add this to a `data/` folder in your repo 
3) Add the template Rmarkdown file, `git_fishes_student.Rmd` that was provided on wattle. You'll use this file to work through the tasks and answer questions. 

**STOP**: Before moving on, it's a good time to establish some good *GitHub* practices. You have just did an important step -- you added a bunch of new files. It's time stage these files and commit them so that you have a record. Use *GitHub Desktop* to do this. 

This is also a very good point to make sure that you understand relative path names fo coding. Wait, "relative what?". Your working directory can be considered the 'lowest' level of your project. The starting point, if you will. R needs to know where your files are that you want to load. Many people might be familiar with using the `setwd()` function to tell R where your files are that you need to load. This is problematic because everyone's path to a given working directory is different, and so, your code will not work on others' computers. Even across your own computers!

Lucky, RStudio project files take away the main issue by creating a project file that allows anyone to click on it to open the working directory to the same "spot". Having said that, if you start building structure (i.e., folders) in your working directory or repo than you need to understand how to navigate between folders to load and write files in the places that you want. 

Make sure you have added a `data/` folder to your working directory that you just cloned down. Think about how you would write some code to load in a data file that is within this folder. There are a few useful shortcuts you can use. For example, if you use `.` it means 'start from the current working directory'. That is the RStudio project file location if you click on a RStudio project. If you use `..` it means "start from the directory or folder one step back from the existing working directory".

>**Question 3**: **How would you write the path name to load in a data file from the data folder?**

Write your answer in the code chunk below:

```{r, loaddata}
# Give the path of row data
path <- "./data/OA_activitydat_20190302_BIOL3207.csv"
# Read the data 
data_raw <- read_csv(path)

```

Let's say that you added a new data folder that was inside an output folder (i.e., `output/data`) to your working directory. The purpose of this folder is to store and track your cleaned up data frame after you have done all your data wrangling and corrections. 

>**Question 4**: Using the `write_csv` function how would you write the path name to save this file to `output/data`?

```{r, write}
# Give the path of edited data
path <- "./output/data/data_raw.csv"
# Write the data
write_csv(data_raw, file = path)

```


# **Task 4**

We're ready for some coding! Lets do some coding and wrangling of the `OA_activitydat_20190302_BIOL3207.csv` data that we will use for the workshop. Note above, the `loaddata` code chunk should have already written the code to load the data file. At this point, we're assuming it's in your working space. If not, make sure you run the `loaddata` code chunk. 

First, write some code below to remove missing data

```{r, rmMiss}
# Code to removing missing data from the `OA_activitydat_20190302_BIOL3207.csv` data frame. 
data_narm <- data_raw %>% filter(complete.cases(.))
# Have a quick look
head(data_narm, 10)
```

Second, drop out irrelevant columns and check that there are no spelling issues in `species` and `treatment`. Create a table of summary data that includes: 1) the mean, 2) the standard error and 3) the sample sizes of unique fish across ALL six fish species for each treatment. This will also help you detect any spelling errors. You can use the R package [`flextable`](https://ardata-fr.github.io/flextable-book/) to print out the results in a nice neat format! If you haven't heard about `flextable` spend 10 or so minutes having a look at it's functionality. It's incredible! You'll use this for tables throughout.

```{r summaryTab}
# Drop irrelevant columns
data_useful <- data_narm[, c(-1, -2, -5, -7, -9)]
# Have a quick look
head(data_useful, 10)
# Check spelling in species and treatment but also generate a summary table
data_group <- data_useful %>% group_by(species, treatment) %>%  
  # Calculate mean and standard error of "sl" and "activity"
  mutate(sample_size = length(activity), mean_activity = mean(activity), se_activity = sd(activity) / (sqrt(length(activity))))
# Delete duplicate data and sort
data_summary <- data_group %>% .[, c(-3, -4)] %>% .[!duplicated(.), ] %>% .[order(.$species, .$treatment), ]
# Use flextable to render the summary table in a tidy format
flextable(data_summary) %>% add_header_lines(., values = "Table 1: Summary of data") %>% align(., align = "left")
# There is no abnormal sample size, which means no spelling mistakes
```

**STOP**: Before moving on, it's a good time to establish some good *GitHub* practices. You have just done an important step. It's time to save this file, stage it and commit it so that you have a record. Push these changes up using *GitHub Desktop*. It's important to do this frequently. It's probably not needed after every line of code, but it's good to do this when you have completed an important coding step. Of course, there's no harm in doing it more often. It will provide fine-scale tracking for you!

>**Question 5**: The new version of your Rmarkdown file should now be up on *GitHub*. In the browser window click on your most recent commit. Have a look at the file versioning system. You will notice two files side-by-side. Describe what you notice is being presented online. What do the red and green highlights mean?

```{r answer5, echo=TRUE, eval=FALSE}
## Write your answer here....remember to use '#" in front of your text.
#The left side shows all changes in my repo compared to last time. The right side shows the content of my Rmarkdown file, in which the left line number shows the changed codes in the previous version and highlighted in red; the right line number shows the new codes this time and highlighted in green.
```

# **Task 5**

Ignoring figures can be important because they take up quite a lot of space in your *GitHub* repo. For example, huge data files, or figures (e.g., png) can take up a tonne of space. We also might not need to save and track these because we can recreate them with our own code or re-download, process, save and track what we need. 

`.gitignore` files are used to control what *Git* tracks and what it ignores. You should have created a new folder path: `output/figures/`. Write some code now to create a pretty figure using ggplot that shows the difference between control and acidification treatments for each of the fish species in the data set:

```{r, prettyfig, fig.align='center', fig.cap="mean activity for each treatment for each species"}
# ggplot figure showing mean activity for each treatment (Control, OA) for each species.
Fig1 <- ggplot(data_group, aes(x = treatment, y = mean_activity, fill = treatment)) +
  geom_col() +
  facet_wrap(~ species, nrow = 2)
Fig1
# Save the plot
ggsave('./output/figures/mean_activity.png')
```

**Stretch Task**: The Clark et al. 2020 paper plots some pretty pictures on their figures. You have access to a folder called "pics/". Add the pics of the difference species from the "pics/" folder to your new plot. Explore the function `annotation_raster()` which might help you achieve this goal.

Note the code chunk used to make the figure. It has a `fig.cap` argument. That means Rmarkdown knows it's a figure and it will allow you to create a figure reference call. In other words, we can refer to our Figure \@ref(fig:prettyfig) by referring to the label for the chunk. This will automatically make a legend for us too (assuming you add one in). The same concept applied to Tables but the legend goes above these.

Now that you have the figure you may also want to write / save it as a separate file. Use `ggsave` function to save the figure(s) to your new `output/figures/`:

```{r, savefig, fig.cap="mean activity for each treatment for each species with pictures"}
# Load the pictures
pacantho <- readPNG('./pics/acantho.png')
pambon <- readPNG('./pics/ambon.png')
pchromis <- readPNG('./pics/chromis.png')
phumbug <- readPNG('./pics/humbug.png')
plemon <- readPNG('./pics/lemon.png')
pwhitedams <- readPNG('./pics/whitedams.png')
# Make a new plot with pics
# For acantho 
acantho <- data_group %>% filter(species == "acantho")
p1 <- ggplot(acantho, aes(x = treatment, y = mean_activity, fill = treatment)) + 
  annotation_raster(pacantho, -Inf, Inf, -Inf, Inf) +
  geom_col(alpha = 0.8) +
  ggtitle("Mean activity of Acantho") +
  theme(legend.position = 'none', axis.title.x=element_blank(), axis.text.x=element_blank())
# For ambon 
ambon <- data_group %>% filter(species == "ambon")
p2 <- ggplot(acantho, aes(x = treatment, y = mean_activity, fill = treatment)) + 
  annotation_raster(pambon, -Inf, Inf, -Inf, Inf) +
  geom_col(alpha = 0.8) +
  ggtitle("Mean activity of Ambon") +
  theme(legend.position = 'none', axis.title.y=element_blank(), axis.text.y=element_blank()) +
  theme(legend.position = 'none', axis.title.x=element_blank(), axis.text.x=element_blank())
# For acantho 
chromis <- data_group %>% filter(species == "chromis")
p3 <- ggplot(acantho, aes(x = treatment, y = mean_activity, fill = treatment)) + 
  annotation_raster(pchromis, -Inf, Inf, -Inf, Inf) +
  geom_col(alpha = 0.8) +
  ggtitle("Mean activity of Chromis") +
  theme(legend.position = 'none', axis.title.y=element_blank(), axis.text.y=element_blank()) +
  theme(legend.position = 'none', axis.title.x=element_blank(), axis.text.x=element_blank())
# For acantho 
humbug <- data_group %>% filter(species == "humbug")
p4 <- ggplot(acantho, aes(x = treatment, y = mean_activity, fill = treatment)) + 
  annotation_raster(phumbug, -Inf, Inf, -Inf, Inf) +
  geom_col(alpha = 0.8) +
  ggtitle("Mean activity of Humbug") +
  theme(legend.position = 'none')
# For acantho 
lemon <- data_group %>% filter(species == "lemon")
p5 <- ggplot(acantho, aes(x = treatment, y = mean_activity, fill = treatment)) + 
  annotation_raster(plemon, -Inf, Inf, -Inf, Inf) +
  geom_col(alpha = 0.8) +
  ggtitle("Mean activity of Lemon") +
  theme(legend.position = 'none', axis.title.y=element_blank(), axis.text.y=element_blank())
# For acantho 
whitedams <- data_group %>% filter(species == "whitedams")
p6 <- ggplot(acantho, aes(x = treatment, y = mean_activity, fill = treatment)) + 
  annotation_raster(pwhitedams, -Inf, Inf, -Inf, Inf) +
  geom_col(alpha = 0.8) +
  ggtitle("Mean activity of Whitedams") +
  theme(legend.position = 'none', axis.title.y=element_blank(), axis.text.y=element_blank())
# Patch the six pics
pall <- p1 + p2 + p3 + p4 + p5 + p6
pall
# Use ggsave to save the figure
ggsave('./output/figures/mean_activity_fish.png', )
```

>**Question 6**: Given that you have added `output/figures/` to your `.gitignore` file describe what you notice about what you see in *GitHub Desktop*. 

```{r}
## Write your answer here
# It seems like nothing happens in the "Changes" part of GitHub Desktop, because changes in the figures file has been "ignored".
```

Last question for this task. I promise! It's important to think very carefully about what you track and ignore.

>**Question 7**: Assume that you added the `pics/` folder to your working directory to plot pictures of each fish on your figure. Do you want to track the files in the pic/ folder on GitHub despite them being .png files? Explain your reasoning. 

```{r, answer6}
## Add your answer here
# I think it is not a bad idea to track these png files (and I have tried they can indeed be tracked) because they are source of our new plot above. Changes in these pictures will also change our final outcomes, so we should track them.
```

# **Task 6**
This task involves teaming up with a collaborator. Exchange *GitHub* username details and add each other to your repo. Clone each others' repo on to your computer. Re-run their code. Does it work? If not, correct it for them. Explain to them WHY it didn't work. After all, they are right beside you! Think carefully about this. Will it still run on their computer if you have corrected it in a certain way?

Now, lets create a new figure in the code block below that simplifies the one produced in **Task 5**. Instead of all species, lets just plot three of the species (chromis, lemon, and acantho). In the figure code chunk make sure you add the necessary arguments (e.g., `fig.cap`) so that you can refer to Figure \@ref(fig:collabFig).

```{r, collabFig, echo=TRUE, fig.cap="mean activity for each treatment for three species"}
# You want to make changes to your collaborators figure in Task 5. Maybe you want to create a figure that focuses only on three fish species instead of the 5. More specifically, chromis, lemon, and acantho. Add code here to revise their figure to do that.

```


# **Task 7**
This task involves creating and resolving conflicts. Conflicts in files are denoted with specific markers. They look like this when you open a file with conflicts.

 <<<<<<<<< HEAD
  
  THIS IS YOUR CODE
  
 ==============
  
  THIS IS YOUR PARTNERS CODE
  
 !>>>>>>>>928731027301723

Resolving is easy. Decide on what changes you think are the best to proceed with and remove conflict markers. 

>**Stretch Task**: Try creating another conflict in the `collabFig` code chunk of the Rmarkdown file. Resolve the conflict again. More practice doing this is always good!

Once you have figured out how to create and solve conflicts it's time to update the README file with a little more detail about your project and the general workflow. The *GitHub* webpage uses the README file as a sort of introduction to the project. 

**Task**: Provide details about the workflow (i.e., which files are used, when and why) and write a detailed description of the data file used. Include the details about what the column means and which data file someone should use. 

Think about what you would need to know to make sure you can replicate a study. Provide these details so they are easy to find on the README.

# **Task 8**
There's not too much to do in this task on the coding front! You just need to create a *GitHub* issue and create a 'To Do' list on *GitHub* for you and your collaborator. 

# **Task 9**
Here, run some statistical tests to determine, for each species, whether the control vs high $CO^2$ treatments differ significantly from each other and in what direction. Provide the difference in means, their 95% confidence intervals, t-statistic, df and p-value.

>**Stretch Task**: You can of course do this for each species seperately, but those who want a challenge, think about how you might use a loop or even some wrangling methods you have already learnt from the tidyverse to run these tests across all 6 species in a single block of code. If you're familiar with functions, you can even think about writing your own function! All these strategies will avoid having to copy and paste large chunks of code. If you're repeating anything, writing functions and loops are good ways to simplify.

```{r, stats, echo=TRUE, eval=TRUE}
# Add your code here
# Add a repeat time
n_rep <- length(levels(as.factor(data_group$species))) * length(levels(as.factor(data_group$treatment)))
# Add a list to store filtered data
data_sort <- list(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)
# Add a vector to store t-statistic
t_statistic <- 1:6
# Add a tibble to store results
t_result <- tibble(species = c("1", "1", "1", "1", "1", "1"), mean_diff = 1.1:6.1, CI_lower = 1.1:6.1, CI_upper = 1.1:6.1, t = 1.1:6.1, df = 1.1:6.1, p = 1.1:6.1)
# Use for loop to calculate results
for (i in seq(1, n_rep, 2)) {
  # Filter data by species and treatment
  data_sort[[i]] <- data_useful %>% filter(species == levels(as.factor(data_useful$species))[(i + 1) / 2] & treatment ==	"control")
  data_sort[[i + 1]] <- data_useful %>% filter(species == levels(as.factor(data_useful$species))[(i + 1) / 2] & treatment ==	"CO2")
  # Do t.test
  tresult <- t.test(data_sort[[i]]$activity, data_sort[[i + 1]]$activity)
  # Write t_statistic into the vector
  t_statistic[(i + 1) / 2] <- tresult$statistic
  # Write results into the tibble
  t_result[((i + 1) / 2), 1] <- levels(as.factor(data_group$species))[(i + 1) / 2]
  t_result[((i + 1) / 2), 2] <- tresult$estimate[2] - tresult$estimate[1]
  t_result[((i + 1) / 2), 3] <- tresult$conf.int[1]
  t_result[((i + 1) / 2), 4] <- tresult$conf.int[2]
  t_result[((i + 1) / 2), 5] <- tresult$statistic
  t_result[((i + 1) / 2), 6] <- tresult$parameter
  t_result[((i + 1) / 2), 7] <- tresult$p.value
}
```

```{r, table1, echo=TRUE, eval=TRUE, tab.cap = "Table 2: Summary of t test"}
# Using the resulting object created above, which should be a table with all the summary statistics, t, df and p-value for each species create a table. Note that there is a tab.cap argument in the chunk arguments. Write a caption here. 
# Use flextable to render the summary table in a tidy format
flextable(t_result) %>% add_header_lines(., values = "Table 2: Summary of t test") %>% add_footer_lines(., values = c("mean_diff, mean difference of activity of treatnent and control (treatment - control)", "CI_lower, lower of the 95% confidence interval", "CI_upper, upper of the 95% confidence interval", "t, t-statistic", "df, degree of freedom", "p, p-value"))
# We can see the treatment (CO2) only affect species humbug and lemon significantly with p-value 0.021 and 0.071, respectively. The mean difference of the two are both positive, which means CO2 lead to greater activity value in directions.
```

Now that you have a table, you can reference it within a document. For example, you can make a call to Table \@ref(tab:table1) by referring to the name of the code chunk. When you knit the html it will create a hyperlink to your table and insert a legend above the table for you. How cool is that!?

> **Question 8**: Pick one of your favorite species and write about the results to a reader. Write in the Rmarkdown file below what 1) the means and mean differences between control and acidification treatment is along with 2) the 95% confidence intervals of the difference

You can write your blurb below this. Before you do that, a few cool features of Rmarkdown. You can actually code in objects so that, when they are rendered they replace the inline code chunk with the result. To give you an example, an inline code chunk is written as follows: `r "add code here"`. When you render the document, whatever you place in the "add code here" section will be rendered. In this case, we are giving a string, so it simply just adds that in the place where the code is, render and see for yourself. 

Moving forward on that you can also add in an object and whatever that objects value is will also be spit out. For example, consider the following: `r x = 10; x`. What will happen? Well, it will place in the value 10 when rendered. Again, if you don't believe me, check for yourself by rendering the document. 

This is all **VERY** cool because that means if your code or data change than you can update your entire report very fast. It's also 100% reproducible. We know exactly where every single value in your report comes from. This is all pretty helpful when you want to check your code and report side-by-side. Now that you have a bit more detail fill in the following:

Mean activity for `r "whitedams"` in the control group was `r tresult$estimate[1]` (s / min) compared to the OA treatment group, which was `r tresult$estimate[2]` (s / min). The difference between control and OA treatment means was `r tresult$estimate[2] - tresult$estimate[1]` (s / min) (95% CI: `r tresult$conf.int[1]` to `r tresult$conf.int[2]`). 

Now, using what you just learnt, describe what the null hypothesis being tested was and provide statistical evidence (t-statistic, df, and p-value) to support your conclusion about whether we can reject the null hypothesis. Again, make sure you use in-line code. Write you answer below:

**Write your answer here**

Null hypothesis: there is no significant difference between activity of CO2 group and control group of whitedams species.
We can see the degree of freedom is `r tresult$parameter`, calculate t-statistic is `r tresult$statistic` and p-value is `r tresult$p.value`. The p-value is greater than alpha = 0.05, so we cannot reject null hypothesis. 

Re-analyse the data for a single species using permutations instead of a t-test. Do your results differ?

>**Stretch Task**:  If you really want a challenge try doing permutation tests for each species. Again, loops, functions or tidyverse (or even combinations might help). 

```{r, stretch2, echo=TRUE}
# Add your code here.
# Add a repeat time for each species
n_rep_species <- length(levels(as.factor(data_group$species)))
# Add a repeat time for permuted
n_rep_permuted <- 100
# Add a list to store filtered data
data_species <- list(1, 2, 3, 4, 5, 6)
# Add a vector to store results for each species
permuted_result <- 1:6
# Add a vector to store results for each sample
samp_dist <- 1 : n_rep_permuted
# Filter data by species
for (i in 1 : n_rep_species) {
  
  data_species[[i]] <- data_useful %>% filter(species == levels(as.factor(data_group$species))[i])
}
# Use for loop to calculate results
for (k in 1 : n_rep_species) {
  for (j in 1 : n_rep_permuted) {
    # Re-order the activity
    permuted_treatment <- data_species[[k]] %>% mutate(activity = activity[sample(row_number())])
    # Do t-test
    permuted_t_test_results <- t.test(permuted_treatment$activity[which(permuted_treatment$treatment == "control")], permuted_treatment$activity[which(permuted_treatment$treatment == "CO2")])
    # Write the t-statistic into the vector
    samp_dist[j] <- permuted_t_test_results$statistic
  }
  # Judge whether the t-statistic are extreme than original one
  p_tibble <- tibble(value = samp_dist, extreme = (abs(samp_dist) > abs(t_statistic[k])))
  # Calculate p-value
  permuted_result[k] <- sum(p_tibble$extreme == T) / n_rep_permuted
}
# Show the results for each species in a table
permuted_tibble <- tibble(species = levels(as.factor(data_useful$species)), p.p = permuted_result, p.t = t_result$p)
flextable(permuted_tibble, cwidth = 2, cheight = 2) %>% add_header_lines(., values = "Table 3: p-value from permutation test") %>% add_footer_lines(., values = c("p.p, p-value from permutation test", "p.t, p-value from t-test")) 
```

Below. Add a few sentences for the species (or multiple species) you talked about above to describe the permutation results:

**Add your text and inline code chunks here**
We can see the p-values from permutation test are similar with the p-values from t-test, in which only humbug and lemon species have significant difference between control and CO2 groups.

# **Task 10**

This is a stretch task on the use of *GitHub* and the challenges (or maybe lack of challenges) of reproducing others' work. If you finish the above tasks, then, have a crack at this one. See the html for details.
